<html><head><title>Parallel rendering using POVRAY on a computer farm</title></head>
<body bgcolor="#ffffff">

<table width="100%"><tbody><tr><td>
<center>
<h1>Parallel Rendering</h1>
<h3>Using POVRAY on a Computer Farm</h3>
Written by <a href="http://astronomy.swin.edu.au/%7Epbourke/povray/">Paul Bourke</a><br>
Example model courtesy of Stèfan Viljoen<br>
Trees by Paul Dawson, lens flare and city by Chris Colefax.<br>
August 1999
</center>
</td><td align="right" width="200">
<img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/overfsmall.gif" border="1">
</td></tr></tbody></table>

<p></p><hr><p>

</p><p align="justify">
Given a number of computers and a demanding POVRAY scene to render, there are
a number of techniques to distribute the rendering among the available
resources. If one is rendering an animation
then obviously each computer can render a subset of the total number of
frames. The frames can be sent to each computer in contiguous chunks or
in an interleaved order, in either case a preview (every N'th frame)
of the animation can generally be
viewed as the frames are being computed. Typically an interleaved order
is preferable since parts of the animation that may be more computationally
demanding are split more evenly over the available computing resources.
</p>

<p align="justify">
In many cases even single frames can take a significant time to render.
This can occur for all sorts of reasons: complicated geometry, sophisticated
lighting (eg: radiosity), high antialiasing rates, 
or simply a large image size. The usual way to render such scenes
on a collection of computers is to split the final image up into pieces,
rendering each piece on a different computer and sticking the pieces
together at the end. POVRAY supports this rendering by the ini file
directives
</p>

<ul>
Height=n<br>
Width=n<br>
Start_Row=n<br>
End_Row=n<br>
Start_Column=n<br>
End_Column=n<br>
</ul>

<p align="justify">
There are a couple of different ways an image may be split up, by row,
column, or in a checker pattern.
</p>
<center><img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/chunks.gif"></center>

<p align="justify">
It turns out that it is normally easier to split the
image up into chunks by row, these are the easiest to paste together
automatically at the end of the rendering. Unfortunately, the easiest
file formats do deal with in code are TGA and PPM, in both these cases
writing a "nice" utility to patch the row chunks together is fustrated
by an error that POVRAY makes when writing the images for partial frames. If the
whole image is 800 x 600 say and we render row 100 to 119, the PPM
file should have the dimensions in its header state that the file is
800 x 20. Unfortunately it states that the image is 800 x 600 which
is obviously wrong and causes most image reading programs to fail!
I'd like to hear any justification there might be for this apparently
trivial error by POVRAY.
</p>

For example the ini file might contain the following<br>
<ul>
Height=600<br>
Width=800<br>
Start_Row=100<br>
End_Row=119<br>
</ul>

<p align="justify">
A crude C utility to patch together a collection of PPM files of the
form filename_nnnn.ppm, is given here <a href="http://astronomy.swin.edu.au/%7Epbourke/povray/parallel/combineppm.c">(combineppm.c)</a>.
You can easily modify it for any
file naming conventions you choose that are different from those used
here.
</p>

<p align="justify">
So, the basic procedure if you have N machines on which to render your
scene is to create N ini files, each one rendering the appropriate row chunk.
Each ini file creates one output image file, in this case, in PPM format.
When all the row chunks are rendered the image files are stuck together.
</p>

<p align="justify">
How you submit the ini files to the available machines will be left up the
reader as it is likely to be slightly different in each environment. Two
common methods are: using rsh with the povray command line prompt, or 
writing a simple application for parallel libraries such as MPI or PVM.
The later two have the advantage that they can offer a degree of 
automatic error recovery if a row chunk fails to render for some reason.
</p>

<p align="justify">
The following crude C code <a href="http://astronomy.swin.edu.au/%7Epbourke/povray/parallel/makeset.c">(makeset.c)</a> 
illustrates how the ini files might be automatically created. Of course
you can add any other options you like to the ini file.
The basic arithmetic for the start and stop row chunks is given below,
note that POVRAY starts its numbering from row 1 not 0!
</p>
<ul>
Start_Row=(i * HEIGHT) / N + 1<br>
End_Row=((i + 1) * HEIGHT) / N
</ul>

<p align="justify">
With regard to performance and efficiency.....if each row chunk takes about
the same time to render then one gets a linear improvement with the number
of processors available. (This assumes that the rendering time is much longer
compared to the scene loading time). Unfortunately this is not always the
case, the rows across the sky might take a trivial length of time to render
while the rows that intersect the interesting part of the scene might take
a lot longer. In this case the machines that rendered the fast portions
will stand idle for most of the time. For example consider the following
scene rendered simultaneously in equal height 
slices on 48 machines, there is over
a factor 1000 in the rendering time for the dark row chunks compared to the
lighter shaded row chunks. In this case the cause is easy to determine,
any row with a tree blows out the rendering time.
</p>
<center><img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/rendertime.gif"></center>

<p align="justify">
One way around this is to split the scene into many more
row chunks than there are computers and write a utility that submits jobs
to machines as they become free. This isn't hard to do if you base your
rendering around rsh and it is reasonably easy with MPI or PVM once
you understand how to use those libraries.
</p>

<table cellpadding="0" cellspacing="0" width="100%"><tbody><tr><td valign="top">
<p align="justify">
Another and perhaps neater way is to create row chunks of different
heights according to the estimated rendering time. The script used to
render the final image can be modified to render a much smaller image
with the same number of row chunks. An estimate of the time for the
different rows can be used to create narrow row chunks in the complex
regions and wide row chunks in the fast rendering regions. So, for the
example above, the bottom part of the image might be rendered with
row chunks only a few pixels high while the top portion would be rendered
with much taller chunks.
</p>
</td><td align="right" valign="top" width="150">
<img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/rowchunks.gif">
</td></tr></tbody></table>

<p align="justify">
<b>Note</b><br>
There is an inefficiency as the chunks become narrower and antialiasing is
used. PovRay will normally reuse traced rays when it can for adjacent
pixels, for example, the filled circles below are only calculated once
when PovRay is calculating the pixels shown (blue) but they will calculated
twice if the image is split and the pixels calculated separately.
</p>
<center><img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/antialias.gif"></center>
<p>

</p><p></p><hr width="50%"><p>

</p><p align="justify">
All these techniques assume one has a scene that takes a significant
time to render. The experimentation described above was performed on
a scene provided by Stefan Viljoen that for fairly obvious reasons (trees)
is extremely CPU demanding. If you would like to experiment yourself,
the model files are provided here (<a href="http://astronomy.swin.edu.au/%7Epbourke/povray/parallel/overf.tar.gz">overf.tar.gz</a>).
The scene, as provided, rendered with the following ini file took
just over 16 hours on a farm of 48 identical DEC XP1000 workstations.
</p>
<ul>
Width=1200<br>
Height=900<br>
Antialias=On<br>
Antialias_Threshold=0.3<br>
Output_File_Name=overf.ppm<br>
Input_File_Name=overf.pov<br>
Output_File_Type=P<br>
Quality=9<br>
Radiosity=off<br>
</ul>

A reduced version of the rendering is shown below<p>
</p><center><img src="Parallel%20rendering%20using%20POVRAY%20on%20a%20computer%20farm_files/overf.jpeg" border="1"></center><p>

</p></body></html>